{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d357fdd-7de5-4ce3-a54c-0bee53ef50d7",
   "metadata": {},
   "source": [
    "## <center> Project - Sentiment Analysis on Suka Dessert</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985071f6-e7c5-4bee-bd0d-f0cafa5ce0b2",
   "metadata": {},
   "source": [
    "#### Group Sixth Sense\n",
    "#### 1) Muhammad 'Umar bin Zolkifle, SW01082397\n",
    "#### 2) Izzat Hatta bin Azizi, SW01082390\n",
    "#### 3) Muhammad Hakimi bin Azizi, SW01082355\n",
    "#### 4) Amirul Farhan bin Kamaruzaman, SW01082374\n",
    "#### 5) Maizatul Aufa binti Zamidi, SW01082394\n",
    "#### 6) Najah Zdafirah binti Mohamad Zakir, IS01082508"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b3a7b76-1fb3-4e0b-a31c-9c987fbef2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "svm_report = LinearSVC(dual='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e89a1fb-8317-44bc-a738-e82ff2a7fe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Dataset\n",
    "file_path = \"processed-reviewsv2.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5074d8a-7427-4082-951a-fb4f3075cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join tokens from 'processed_review' column into a single string per row\n",
    "df['clean_text'] = df['processed_review'].apply(lambda x: \" \".join(eval(x)) if isinstance(x, str) else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30281e0d-cc99-4f87-8506-c20d3805fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply keyword-based sentiment labeling on the cleaned text\n",
    "positive_keywords = ['good', 'delicious', 'nice', 'great', 'tasty', 'love', 'friendly', 'awesome', 'perfect', 'best']\n",
    "negative_keywords = ['bad', 'worst', 'slow', 'expensive', 'disappointed', 'not', 'poor', 'rude', 'overpriced', 'cold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ecd9902-15e8-41d4-8b93-ea27234085cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentiment(text):\n",
    "    text = str(text).lower()\n",
    "    if any(word in text for word in positive_keywords):\n",
    "        return 'positive'\n",
    "    elif any(word in text for word in negative_keywords):\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "df['Sentiment'] = df['clean_text'].apply(label_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc7ccb02-4da4-4a1f-a2db-0b2d5f5d06e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000)\n",
    "X = tfidf.fit_transform(df['clean_text'])\n",
    "y = df['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abc00759-7a8f-4ae6-b246-004fe0902727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1c23476-588b-47ec-be85-2635b1f18800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Evaluation Function\n",
    "def evaluate_model(model, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    df_report = pd.DataFrame(report).transpose()\n",
    "    print(f\"\\n--- {model_name} Evaluation Report ---\")\n",
    "    print(df_report[[\"precision\", \"recall\", \"f1-score\"]])\n",
    "    return df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df8e9c2f-9dd2-49f9-972a-4681729b752c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Logistic Regression Evaluation Report ---\n",
      "              precision    recall  f1-score\n",
      "negative       0.000000  0.000000  0.000000\n",
      "neutral        0.772727  0.680000  0.723404\n",
      "positive       0.660000  0.916667  0.767442\n",
      "accuracy       0.694444  0.694444  0.694444\n",
      "macro avg      0.477576  0.532222  0.496949\n",
      "weighted avg   0.598308  0.694444  0.634903\n",
      "\n",
      "--- Naive Bayes Evaluation Report ---\n",
      "              precision    recall  f1-score\n",
      "negative       0.000000  0.000000  0.000000\n",
      "neutral        1.000000  0.560000  0.717949\n",
      "positive       0.620690  1.000000  0.765957\n",
      "accuracy       0.694444  0.694444  0.694444\n",
      "macro avg      0.540230  0.520000  0.494635\n",
      "weighted avg   0.657567  0.694444  0.632266\n",
      "\n",
      "--- SVM (Linear) Evaluation Report ---\n",
      "              precision    recall  f1-score\n",
      "negative       0.666667  0.181818  0.285714\n",
      "neutral        0.703704  0.760000  0.730769\n",
      "positive       0.738095  0.861111  0.794872\n",
      "accuracy       0.722222  0.722222  0.722222\n",
      "macro avg      0.702822  0.600976  0.603785\n",
      "weighted avg   0.715241  0.722222  0.694826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maiza\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train and Evaluate Models\n",
    "logistic_report = evaluate_model(LogisticRegression(), \"Logistic Regression\")\n",
    "naive_bayes_report = evaluate_model(MultinomialNB(), \"Naive Bayes\")\n",
    "svm_report = evaluate_model(LinearSVC(), \"SVM (Linear)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e831c247-d9b5-49fa-80b6-ca0479a45653",
   "metadata": {},
   "source": [
    "## Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8711eb4f-1c30-420f-bd55-e7649e84f02e",
   "metadata": {},
   "source": [
    "Methods Used:\n",
    "Logistic Regression, Naive Bayes, and SVM (Linear) for sentiment classification (positive, neutral, negative).\n",
    "\n",
    "Why These Methods:\n",
    "\n",
    "Logistic Regression:\n",
    "This is a simple and popular method often used first when trying to solve classification problems. It works well for both two or more categories (like positive, neutral, and negative) and gives good results when the data is fairly straightforward.\n",
    "\n",
    "Naive Bayes:\n",
    "This method is fast and works well with text, which makes it a good choice for sentiment analysis. Even though it makes some simple assumptions about the data, it often gives surprisingly good results for tasks like this.\n",
    "\n",
    "SVM (Linear):\n",
    "SVM is a strong method for finding the best line or boundary to separate categories. When using a linear version, itâ€™s faster and still works well, especially with text data where there are many features (like words).\n",
    "\n",
    "Naive Bayes is known to work well with text classification due to its simplicity and efficiency.\n",
    "\n",
    "SVM is powerful for high-dimensional data like TF-IDF vectors and is often used in text classification tasks for its robustness and accuracy.\n",
    "\n",
    "Testing all three provides a comparison of performance to choose the best model for real-world application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbd5c30-8b32-411a-9dba-92260ed72f02",
   "metadata": {},
   "source": [
    "#### Model Effectiveness\n",
    "Evaluation metrics used: Accuracy, Precision, Recall, F1-Score (per class)\n",
    "| Model               | Accuracy  | Best F1-Score Class | Weakness Observed                 |\r\n",
    "| ------------------- | --------- | ------------------- | --------------------------------- |\r\n",
    "| Logistic Regression | 69.4%     | Positive (0776)     | Poor on **negative** class (0.00) |\r\n",
    "| Naive Bayes         | 69.4%     | Positive (0.77)     | No prediction for negative        |\r\n",
    "| SVM (LinearSVC)     | **72.2%** | Positive (0.79)     | Best balanced performance         |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091a52f4-b162-4690-bbff-8fec08f31b30",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "\n",
    "SVM outperformed the others with the highest accuracy and better performance on both neutral and negative classes.\n",
    "\n",
    "Naive Bayes and Logistic Regression performed well on positive and neutral but failed to predict the negative class effectively, likely due to class imbalance or lack of strong negative signals in the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34427e8b-a4c4-46a6-b565-8aa0109dcf1e",
   "metadata": {},
   "source": [
    " #### Visualize Results & Extract Insights\n",
    "\n",
    "##### What patterns did you discover?\n",
    "Most reviews were positive, which aligns with the strong performance of all models in that category.\n",
    "\n",
    "Neutral reviews were also common and well-handled by all models.\n",
    "\n",
    "Negative reviews were sparse and harder to detect, causing poor performance in that category for some models.\n",
    "\n",
    "##### What insights can be derived from your analysis?\n",
    "Suka Dessert receives mostly positive sentiment, indicating customer satisfaction.\n",
    "\n",
    "Few negative reviews suggest occasional issues (e.g., service, pricing) that could be further analyzed.\n",
    "\n",
    "Sentiment trends could help monitor business performance over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63be7a97-d466-4753-8c14-15fd13927ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
